{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6686201e-c144-4caf-9015-5c5dedb57941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import keras\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "image_data = tf.keras.datasets.fashion_mnist\n",
    "(train_images,train_label),(test_images, test_labels) = image_data.load_data()\n",
    "train_images = train_images /255\n",
    "train_images = train_images.astype(float)\n",
    "test_images = test_images /255\n",
    "test_images = test_images.astype(float)\n",
    "\n",
    "train_images=train_images.reshape(len(train_images),28,28,1)\n",
    "test_images=test_images.reshape(len(test_images),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75ab153-51a4-4e6a-a133-967f04f253fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  \n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        activation='relu',\n",
    "        input_shape=(28,28,1)\n",
    "    ),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9ca459-5139-4fd0-8fe8-ffc0ef638000",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(build_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=5,directory='output',project_name=\"Mnist Fashion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd8c119-26c3-4aee-9679-46e3ac667041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 04m 12s]\n",
      "val_accuracy: 0.8793333172798157\n",
      "\n",
      "Best val_accuracy So Far: 0.9100000262260437\n",
      "Total elapsed time: 00h 29m 37s\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(train_images,train_label,epochs=3,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d7a9f-3477-4982-9cd8-14a548aacf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner_search.get_best_models()[0]\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d895d71e-414a-499f-be71-6676d5a9dfe6",
   "metadata": {},
   "source": [
    "\n",
    "Згорткові нейронні мережі (CNN) є більш ефективними для обробки зображень через їхню спеціалізовану архітектуру, яка дозволяє автоматично виявляти та аналізувати просторові залежності у даних. Це робить їх більш ефективними для завдань обробки зображень порівняно зі звичайними нейронними мережами (DNN). Однак DNN можуть бути ефективними для різноманітних інших завдань, які не мають просторової структури даних, таких як розпізнавання тексту або аналіз числових даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c18f0b8d-c46b-4a34-a42b-32d59b0a6192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 175s 465ms/step - loss: 1.6359 - accuracy: 0.5919 - val_loss: 0.6792 - val_accuracy: 0.7897\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 173s 461ms/step - loss: 0.5409 - accuracy: 0.8313 - val_loss: 0.4607 - val_accuracy: 0.8575\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 176s 469ms/step - loss: 0.4041 - accuracy: 0.8723 - val_loss: 0.3822 - val_accuracy: 0.8825\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 175s 467ms/step - loss: 0.3377 - accuracy: 0.8937 - val_loss: 0.3318 - val_accuracy: 0.8983\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 169s 450ms/step - loss: 0.2940 - accuracy: 0.9076 - val_loss: 0.2997 - val_accuracy: 0.9087\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img\n",
    "\n",
    "\n",
    "(xtrain,ytrain),(xtest,ytest)= keras.datasets.mnist.load_data()\n",
    "\n",
    "xtrain=np.dstack([xtrain] * 3)\n",
    "xtest=np.dstack([xtest]*3)\n",
    "xtrain.shape,xtest.shape\n",
    "\n",
    "\n",
    "xtrain = xtrain.reshape(-1, 28,28,3)\n",
    "xtest= xtest.reshape (-1,28,28,3)\n",
    "xtrain.shape,xtest.shape\n",
    "\n",
    "xtrain = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtrain])\n",
    "xtest = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtest])\n",
    "\n",
    "xtrain.shape, xtest.shape\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xtrain,ytrain,test_size=0.2,random_state=5)\n",
    "\n",
    "\n",
    "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
    "for layer in conv_base.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "\n",
    "model = models.Sequential([\n",
    "    conv_base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(xtrain,ytrain,epochs=5,batch_size=128,verbose=True,validation_data=(xtest,ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e589138e-3c51-4259-b121-f0d2570f34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a69ab8a5-a7fe-4c2f-833c-d9745fdabd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "375/375 [==============================] - 38s 102ms/step - loss: 0.2997 - accuracy: 0.9087\n",
      "Test Accuracy: 0.9087499976158142\n",
      "Test Loss: 0.299716591835022\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "loaded_model = load_model(\"my_model.h5\")\n",
    "loss, accuracy = model.evaluate(xtest, ytest)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5749d876-7d75-43f2-a796-1fe7fa80ca47",
   "metadata": {},
   "source": [
    "Перша модель (з VGG16) показала високу точність під час навчання та валідації на перевірочному наборі даних, але має схильність до перенавчання через велику кількість параметрів. Друга модель, згорткова нейронна мережа з автоматично підібраними гіперпараметрами, може бути більш ефективною з точки зору обмеження перенавчання та кращої узагальненості, оскільки вона відбирає оптимальну архітектуру, а не використовує попередньо навчену модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f54ba9-3f2f-4169-bdae-a959e9ee4039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
